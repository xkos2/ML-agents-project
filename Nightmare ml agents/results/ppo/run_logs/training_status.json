{
    "Reach Finish": {
        "checkpoints": [
            {
                "steps": 215477,
                "file_path": "results\\ppo\\Reach Finish\\Reach Finish-215477.onnx",
                "reward": 1.44,
                "creation_time": 1622463695.7464776,
                "auxillary_file_paths": [
                    "results\\ppo\\Reach Finish\\Reach Finish-215477.pt"
                ]
            },
            {
                "steps": 257507,
                "file_path": "results\\ppo\\Reach Finish\\Reach Finish-257507.onnx",
                "reward": 2.0,
                "creation_time": 1622466722.3183787,
                "auxillary_file_paths": [
                    "results\\ppo\\Reach Finish\\Reach Finish-257507.pt"
                ]
            },
            {
                "steps": 267749,
                "file_path": "results\\ppo\\Reach Finish\\Reach Finish-267749.onnx",
                "reward": null,
                "creation_time": 1622618800.945651,
                "auxillary_file_paths": [
                    "results\\ppo\\Reach Finish\\Reach Finish-267749.pt"
                ]
            },
            {
                "steps": 278032,
                "file_path": "results\\ppo\\Reach Finish\\Reach Finish-278032.onnx",
                "reward": null,
                "creation_time": 1622619119.3613465,
                "auxillary_file_paths": [
                    "results\\ppo\\Reach Finish\\Reach Finish-278032.pt"
                ]
            },
            {
                "steps": 286447,
                "file_path": "results\\ppo\\Reach Finish\\Reach Finish-286447.onnx",
                "reward": -2.0,
                "creation_time": 1622619564.3898718,
                "auxillary_file_paths": [
                    "results\\ppo\\Reach Finish\\Reach Finish-286447.pt"
                ]
            }
        ],
        "final_checkpoint": {
            "steps": 286447,
            "file_path": "results\\ppo\\Reach Finish.onnx",
            "reward": -2.0,
            "creation_time": 1622619564.3898718,
            "auxillary_file_paths": [
                "results\\ppo\\Reach Finish\\Reach Finish-286447.pt"
            ]
        }
    },
    "metadata": {
        "stats_format_version": "0.2.0",
        "mlagents_version": "0.25.1",
        "torch_version": "1.7.1+cu110"
    },
    "Rotatepls": {
        "checkpoints": [
            {
                "steps": 0,
                "file_path": "results\\ppo\\Rotatepls\\Rotatepls-0.onnx",
                "reward": null,
                "creation_time": 1622458570.5232563,
                "auxillary_file_paths": [
                    "results\\ppo\\Rotatepls\\Rotatepls-0.pt"
                ]
            }
        ],
        "final_checkpoint": {
            "steps": 0,
            "file_path": "results\\ppo\\Rotatepls.onnx",
            "reward": null,
            "creation_time": 1622458570.5232563,
            "auxillary_file_paths": [
                "results\\ppo\\Rotatepls\\Rotatepls-0.pt"
            ]
        }
    },
    "My Behavior": {
        "checkpoints": [
            {
                "steps": 40965,
                "file_path": "results\\ppo\\My Behavior\\My Behavior-40965.onnx",
                "reward": 0.0,
                "creation_time": 1622480884.4090447,
                "auxillary_file_paths": [
                    "results\\ppo\\My Behavior\\My Behavior-40965.pt"
                ]
            },
            {
                "steps": 43202,
                "file_path": "results\\ppo\\My Behavior\\My Behavior-43202.onnx",
                "reward": -0.7391304347826086,
                "creation_time": 1622481056.4021301,
                "auxillary_file_paths": [
                    "results\\ppo\\My Behavior\\My Behavior-43202.pt"
                ]
            },
            {
                "steps": 53466,
                "file_path": "results\\ppo\\My Behavior\\My Behavior-53466.onnx",
                "reward": null,
                "creation_time": 1622481263.6139338,
                "auxillary_file_paths": [
                    "results\\ppo\\My Behavior\\My Behavior-53466.pt"
                ]
            },
            {
                "steps": 82258,
                "file_path": "results\\ppo\\My Behavior\\My Behavior-82258.onnx",
                "reward": -0.869281045751634,
                "creation_time": 1622481952.2153325,
                "auxillary_file_paths": [
                    "results\\ppo\\My Behavior\\My Behavior-82258.pt"
                ]
            },
            {
                "steps": 85514,
                "file_path": "results\\ppo\\My Behavior\\My Behavior-85514.onnx",
                "reward": -0.9047619047619048,
                "creation_time": 1622482814.6988597,
                "auxillary_file_paths": [
                    "results\\ppo\\My Behavior\\My Behavior-85514.pt"
                ]
            }
        ],
        "final_checkpoint": {
            "steps": 85514,
            "file_path": "results\\ppo\\My Behavior.onnx",
            "reward": -0.9047619047619048,
            "creation_time": 1622482814.6988597,
            "auxillary_file_paths": [
                "results\\ppo\\My Behavior\\My Behavior-85514.pt"
            ]
        }
    },
    "RewardBias": {
        "checkpoints": [
            {
                "steps": 119542,
                "file_path": "results\\ppo\\RewardBias\\RewardBias-119542.onnx",
                "reward": null,
                "creation_time": 1622616591.803038,
                "auxillary_file_paths": [
                    "results\\ppo\\RewardBias\\RewardBias-119542.pt"
                ]
            },
            {
                "steps": 129838,
                "file_path": "results\\ppo\\RewardBias\\RewardBias-129838.onnx",
                "reward": null,
                "creation_time": 1622616773.284488,
                "auxillary_file_paths": [
                    "results\\ppo\\RewardBias\\RewardBias-129838.pt"
                ]
            },
            {
                "steps": 130889,
                "file_path": "results\\ppo\\RewardBias\\RewardBias-130889.onnx",
                "reward": 3.7222222222222223,
                "creation_time": 1622617388.554079,
                "auxillary_file_paths": [
                    "results\\ppo\\RewardBias\\RewardBias-130889.pt"
                ]
            },
            {
                "steps": 131489,
                "file_path": "results\\ppo\\RewardBias\\RewardBias-131489.onnx",
                "reward": 0.0,
                "creation_time": 1622617470.6714184,
                "auxillary_file_paths": [
                    "results\\ppo\\RewardBias\\RewardBias-131489.pt"
                ]
            },
            {
                "steps": 141732,
                "file_path": "results\\ppo\\RewardBias\\RewardBias-141732.onnx",
                "reward": null,
                "creation_time": 1622618369.983775,
                "auxillary_file_paths": [
                    "results\\ppo\\RewardBias\\RewardBias-141732.pt"
                ]
            }
        ],
        "final_checkpoint": {
            "steps": 141732,
            "file_path": "results\\ppo\\RewardBias.onnx",
            "reward": null,
            "creation_time": 1622618369.983775,
            "auxillary_file_paths": [
                "results\\ppo\\RewardBias\\RewardBias-141732.pt"
            ]
        }
    },
    "LogRunner": {
        "checkpoints": [
            {
                "steps": 0,
                "file_path": "results\\ppo\\LogRunner\\LogRunner-0.onnx",
                "reward": null,
                "creation_time": 1622558914.475878,
                "auxillary_file_paths": [
                    "results\\ppo\\LogRunner\\LogRunner-0.pt"
                ]
            },
            {
                "steps": 0,
                "file_path": "results\\ppo\\LogRunner\\LogRunner-0.onnx",
                "reward": null,
                "creation_time": 1622559111.3065617,
                "auxillary_file_paths": [
                    "results\\ppo\\LogRunner\\LogRunner-0.pt"
                ]
            },
            {
                "steps": 0,
                "file_path": "results\\ppo\\LogRunner\\LogRunner-0.onnx",
                "reward": null,
                "creation_time": 1622559300.781525,
                "auxillary_file_paths": [
                    "results\\ppo\\LogRunner\\LogRunner-0.pt"
                ]
            },
            {
                "steps": 45220,
                "file_path": "results\\ppo\\LogRunner\\LogRunner-45220.onnx",
                "reward": 0.0,
                "creation_time": 1622560817.7784169,
                "auxillary_file_paths": [
                    "results\\ppo\\LogRunner\\LogRunner-45220.pt"
                ]
            },
            {
                "steps": 46402,
                "file_path": "results\\ppo\\LogRunner\\LogRunner-46402.onnx",
                "reward": -1.0,
                "creation_time": 1622560880.3285985,
                "auxillary_file_paths": [
                    "results\\ppo\\LogRunner\\LogRunner-46402.pt"
                ]
            }
        ],
        "final_checkpoint": {
            "steps": 46402,
            "file_path": "results\\ppo\\LogRunner.onnx",
            "reward": -1.0,
            "creation_time": 1622560880.3285985,
            "auxillary_file_paths": [
                "results\\ppo\\LogRunner\\LogRunner-46402.pt"
            ]
        }
    },
    "stopdabitch": {
        "checkpoints": [
            {
                "steps": 15439,
                "file_path": "results\\ppo\\stopdabitch\\stopdabitch-15439.onnx",
                "reward": 0.2222222222222222,
                "creation_time": 1622630748.0499942,
                "auxillary_file_paths": [
                    "results\\ppo\\stopdabitch\\stopdabitch-15439.pt"
                ]
            },
            {
                "steps": 42234,
                "file_path": "results\\ppo\\stopdabitch\\stopdabitch-42234.onnx",
                "reward": 0.1111111111111111,
                "creation_time": 1622631184.9070218,
                "auxillary_file_paths": [
                    "results\\ppo\\stopdabitch\\stopdabitch-42234.pt"
                ]
            },
            {
                "steps": 90701,
                "file_path": "results\\ppo\\stopdabitch\\stopdabitch-90701.onnx",
                "reward": 0.46938775510204084,
                "creation_time": 1622632039.657668,
                "auxillary_file_paths": [
                    "results\\ppo\\stopdabitch\\stopdabitch-90701.pt"
                ]
            },
            {
                "steps": 162269,
                "file_path": "results\\ppo\\stopdabitch\\stopdabitch-162269.onnx",
                "reward": 0.30985915492957744,
                "creation_time": 1622639220.3968463,
                "auxillary_file_paths": [
                    "results\\ppo\\stopdabitch\\stopdabitch-162269.pt"
                ]
            },
            {
                "steps": 190924,
                "file_path": "results\\ppo\\stopdabitch\\stopdabitch-190924.onnx",
                "reward": 0.2641509433962264,
                "creation_time": 1622652013.3810258
            }
        ],
        "final_checkpoint": {
            "steps": 190924,
            "file_path": "results\\ppo\\stopdabitch.onnx",
            "reward": 0.2641509433962264,
            "creation_time": 1622652013.3810258
        }
    },
    "findcube": {
        "checkpoints": [
            {
                "steps": 0,
                "file_path": "results\\ppo\\findcube\\findcube-0.onnx",
                "reward": null,
                "creation_time": 1622712598.1303234
            },
            {
                "steps": 3192,
                "file_path": "results\\ppo\\findcube\\findcube-3192.onnx",
                "reward": -2.0,
                "creation_time": 1622712652.1887727
            },
            {
                "steps": 10577,
                "file_path": "results\\ppo\\findcube\\findcube-10577.onnx",
                "reward": -0.38461538461538464,
                "creation_time": 1622712837.5031881
            },
            {
                "steps": 35131,
                "file_path": "results\\ppo\\findcube\\findcube-35131.onnx",
                "reward": 0.935064935064935,
                "creation_time": 1622713367.6689694
            }
        ],
        "final_checkpoint": {
            "steps": 35131,
            "file_path": "results\\ppo\\findcube.onnx",
            "reward": 0.935064935064935,
            "creation_time": 1622713367.6689694
        }
    }
}